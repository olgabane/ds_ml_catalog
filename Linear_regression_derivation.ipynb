{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I work through two derivations for solving linear regession:\n",
    "1. Ordinary least squares. \n",
    "2. Maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares derivation of linear regression\n",
    "\n",
    "$Loss function = \\sum\\limits_{i=1}^n(y_{i}-\\hat{y_{i}})^2$\n",
    "\n",
    "   \n",
    "$\\text{Define loss function and expand:} $  \n",
    "$Q = \\sum\\limits_{i=1}^n(y_{i}-\\hat{y_{i}})^2,   \\hat{y_{i}} = mx_{i} + b $  \n",
    "$Q(m, b) = \\sum\\limits_{i=1}^n(y_{i}- (mx_{i} + b))^2$  \n",
    "$Q(m, b) = \\sum\\limits_{i=1}^n(y_{i}- mx_{i} - b)^2$  \n",
    "$Q(m, b) = \\sum\\limits_{i=1}^n(y_{i}^2 - y_{i}mx_{i} - y_{i}b - y_{i}mx_{i} + m^2x_{i}^2 + mx_{i}b - y_{i}b + mx_{i}b + b^2)$\n",
    "$Q(m, b) = \\sum\\limits_{i=1}^ny_{i}^2 - \\sum\\limits_{i=1}^ny_{i}mx_{i} - \\sum\\limits_{i=1}^ny_{i}b - \\sum\\limits_{i=1}^ny_{i}mx_{i} + \\sum\\limits_{i=1}^nm^2x_{i}^2 + \\sum\\limits_{i=1}^nmx_{i}b - \\sum\\limits_{i=1}^ny_{i}b + \\sum\\limits_{i=1}^nmx_{i}b + \\sum\\limits_{i=1}^nb^2$\n",
    "$Q(m, b) = \\sum\\limits_{i=1}^ny_{i}^2 + \\sum\\limits_{i=1}^nm^2x_{i}^2 + \\sum\\limits_{i=1}^nb^2 - \\sum\\limits_{i=1}^n2y_{i}mx_{i} - \\sum\\limits_{i=1}^n2y_{i}b + \\sum\\limits_{i=1}^n2mx_{i}b $\n",
    "\n",
    "\n",
    "Differentiate with respect to **m** and **b**:\n",
    "\n",
    "$\\frac{\\partial Q}{\\partial m} = 2m\\sum{x_{i}^2} - 2\\sum\\limits_{i=1}^ny_{i}x_{i} + 2b\\sum\\limits_{i=1}^nx_{i}$\n",
    "\n",
    "$\\frac{\\partial Q}{\\partial b} = 2bN - 2\\sum{y_{i}} + 2m\\sum{x_{i}}, \\textit{N = number of points}$\n",
    "\n",
    "\n",
    "We want to minimize m and b, so set both to 0:\n",
    "\n",
    "$2m\\sum{x_{i}^2} - 2\\sum{y_{i}x_{i}} + 2b\\sum{x_{i}} = 0$\n",
    "\n",
    "$2bN - 2\\sum{y_{i}} + 2m\\sum{x_{i}} = 0$\n",
    "\n",
    "\n",
    "Solve for b first:  \n",
    "$b = \\dfrac{2\\sum{y_{i}} - 2m\\sum{x_{i}}}{2N} $  \n",
    "\n",
    "$b = \\dfrac{\\sum{y_{i}} - m\\sum{x_{i}}}{N} $\n",
    "\n",
    "Substitute b and solve for m:\n",
    "\n",
    "\n",
    "$2m\\sum{x_{i}^2} - 2\\sum{y_{i}x_{i}} + 2\\dfrac{\\sum{y_{i}} - m\\sum{x_{i}}}{N}\\sum{x_{i}} = 0$  \n",
    "$m\\sum{x_{i}^2} - \\sum{y_{i}x_{i}} + \\dfrac{\\sum{y_{i}} - m\\sum{x_{i}}}{N}\\sum{x_{i}} = 0$  \n",
    "$m\\sum{x_{i}^2} - \\sum{y_{i}x_{i}} + \\dfrac{\\sum{y_{i}}\\sum{x_{i}} - m(\\sum{x_{i}})^2}{N} = 0$  \n",
    "$mN\\sum{x_{i}^2} - N\\sum{y_{i}x_{i}} + \\sum{y_{i}}\\sum{x_{i}} - m(\\sum{x_{i}})^2 = 0$  \n",
    "$mN\\sum{x_{i}^2} - m(\\sum{x_{i}})^2 = N\\sum{y_{i}x_{i}} - \\sum{y_{i}}\\sum{x_{i}}$  \n",
    "$m(N\\sum{x_{i}^2} - (\\sum{x_{i}})^2) = N\\sum{y_{i}x_{i}} - \\sum{y_{i}}\\sum{x_{i}}$  \n",
    "$m = \\dfrac{N\\sum{y_{i}x_{i}} - \\sum{y_{i}}\\sum{x_{i}}}{N\\sum{x_{i}^2} - (\\sum{x_{i}})^2}$  \n",
    "\n",
    "This solution assumes:\n",
    "1. Normally distributed residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares derivation of linear regression (abridged)\n",
    "\n",
    "1\\. Define loss function and expand:    \n",
    "$Q(m, b) = \\sum\\limits_{i=1}^n(y_{i}-\\hat{y_{i}})^2 = \\sum\\limits_{i=1}^n(y_{i}- (mx_{i} + b))^2$  \n",
    "...  \n",
    "$Q(m, b) = \\sum\\limits_{i=1}^ny_{i}^2 + \\sum\\limits_{i=1}^nm^2x_{i}^2 + \\sum\\limits_{i=1}^nb^2 - \\sum\\limits_{i=1}^n2y_{i}mx_{i} - \\sum\\limits_{i=1}^n2y_{i}b + \\sum\\limits_{i=1}^n2mx_{i}b $\n",
    "\n",
    "2\\. Differentiate with respect to **m** and **b** and set to 0 because we want to minimize error:\n",
    "\n",
    "$\\frac{\\partial Q}{\\partial m} = 0 = 2m\\sum{x_{i}^2} - 2\\sum\\limits_{i=1}^ny_{i}x_{i} + 2b\\sum\\limits_{i=1}^nx_{i}$\n",
    "\n",
    "$\\frac{\\partial Q}{\\partial b} = 0 = 2bN - 2\\sum{y_{i}} + 2m\\sum{x_{i}}$  \n",
    "\n",
    "$\\textit{     N = number of points}$\n",
    "\n",
    "3\\. Solve for **m** and **b**: \n",
    "\n",
    "$m = \\dfrac{N\\sum{y_{i}x_{i}} - \\sum{y_{i}}\\sum{x_{i}}}{N\\sum{x_{i}^2} - (\\sum{x_{i}})^2}$   \n",
    "$b = \\dfrac{\\sum{y_{i}} - m\\sum{x_{i}}}{N} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood derivation of linear regression (abridged)\n",
    "1. PDF for normally-distributed variable: \n",
    "$X \\sim \\mathcal{N}(\\mu, \\sigma^2)$  \n",
    "$ PDF(X) = \\frac{1}{\\sqrt {2\\pi\\sigma^2} }e^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}$  \n",
    "2. PDF, with linear equation in place of the mean.  \n",
    "$ P(y|x; m, b, \\sigma^2) = \\frac{1}{\\sqrt {2\\pi\\sigma^2} }e^{\\frac{-(y-(mx+b))^2}{2\\sigma^2}} $   \n",
    "3. Likelihood function for all observed points (x, y) is the product of the probability density for each point:  \n",
    "$ L(m, b, \\sigma^2) = \\frac{1}{\\sqrt {2\\pi\\sigma^2} }\\prod\\limits_{i=1}^ne^{\\frac{-(y_i-(mx_i+b))^2}{2\\sigma^2}} $  \n",
    "4. Goal: find parameters **b**, **m** and **$\\sigma$** that **maximize _L_.**  \n",
    "  \n",
    "  \n",
    "5. Convert to log likelihood for easier math, **maximize _log(L)_**:  \n",
    "$ log(L) = log[\\frac{1}{\\sqrt {2\\pi\\sigma^2} }\\prod\\limits_{i=1}^ne^{\\frac{-(y_i-(mx_i+b))^2}{2\\sigma^2}}]$   \n",
    "...  \n",
    "$ log(L) = -\\frac{1}{2}log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(y_i-(mx_i+b))^2$ \n",
    "\n",
    "6. Or, **minimize** negative log likelihood:   \n",
    "$ -log(L) = \\frac{1}{2}log(2\\pi\\sigma^2) + \\frac{1}{2\\sigma^2}\\sum\\limits_{i=1}^n(y_i-(mx_i+b))^2$\n",
    "\n",
    "7. Let's _imagine_ that our variance term is a fixed constant.     \n",
    "$-log(L) = \\sum\\limits_{i=1}^n(y_{i}- (mx_{i} + b))^2$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
